"""change_model_data

Revision ID: 01efd5123f7b
Revises: d781d07408ca
Create Date: 2023-12-26 20:50:05.203123

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = "01efd5123f7b"
down_revision = "d781d07408ca"
branch_labels = None
depends_on = None

prediction_class_table = sa.table(
    "prediction_class",
    sa.Column("id", sa.Integer(), nullable=False),
    sa.Column("name", sa.String(), nullable=False),
    sa.Column("created_at", sa.DateTime(), nullable=False, default=sa.func.now()),
    sa.Column("updated_at", sa.DateTime(), nullable=False, default=sa.func.now()),
)

models_table = sa.table(
    "model",
    sa.Column("id", sa.Integer(), nullable=False),
    sa.Column("name", sa.String(), nullable=False),
    sa.Column("description", sa.String(), nullable=False),
    sa.Column("cost", sa.Float(), nullable=False),
    sa.Column("created_at", sa.DateTime(), nullable=False, default=sa.func.now()),
    sa.Column("updated_at", sa.DateTime(), nullable=False, default=sa.func.now()),
    sa.Column("is_active", sa.Boolean(), nullable=False, default=True),
)


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "prediction_class",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("name", sa.String(), nullable=False),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.Column("updated_at", sa.DateTime(), nullable=False),
        sa.PrimaryKeyConstraint("id"),
        sa.UniqueConstraint("name"),
    )
    op.add_column("prediction", sa.Column("input_data", sa.String(), nullable=False))
    op.add_column("prediction", sa.Column("predicted_class_id", sa.Integer(), nullable=True))
    op.create_foreign_key(None, "prediction", "prediction", ["predicted_class_id"], ["id"])
    op.drop_column("prediction", "input")
    op.drop_column("prediction", "output")
    # ### end Alembic commands ###
    models = [
        (1, "base", "Модель предсказывает на основании первого слова", 1.0),
        (2, "logreg_tfidf", "Logreg + TfIdf", 2.0),
        (3, "catboost", "Catboost", 3.0),
    ]
    # select data

    conn = op.get_bind()
    res = conn.execute(sa.select(models_table)).fetchall()
    if len(res) == 0:
        op.bulk_insert(
            models_table,
            [{"id": id, "name": name, "description": description, "cost": cost} for id, name, description, cost in models],
        )

    prediction_classes = [
        (2612, "Mobile Phones"),
        (2614, "TVs"),
        (2615, "CPUs"),
        (2617, "Digital Cameras"),
        (2618, "Microwaves"),
        (2619, "Dishwashers"),
        (2620, "Washing Machines"),
        (2621, "Freezers"),
        (2622, "Fridge Freezers"),
        (2623, "Fridges"),
    ]
    res = conn.execute(sa.select(prediction_class_table)).fetchall()
    if len(res) == 0:
        op.bulk_insert(prediction_class_table, [{"id": id_, "name": name} for id_, name in prediction_classes])


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column(
        "prediction", sa.Column("output", postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=False)
    )
    op.add_column(
        "prediction", sa.Column("input", postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=False)
    )
    op.drop_constraint("prediction_predicted_class_id_fkey", "prediction", type_="foreignkey")
    op.drop_column("prediction", "predicted_class_id")
    op.drop_column("prediction", "input_data")
    op.drop_table("prediction_class")
    # ### end Alembic commands ###
